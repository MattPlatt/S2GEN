{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwwyihopIXfH95oKDoTsJF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattPlatt/S2GEN/blob/main/S2GEN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aK3faedUbz-",
        "outputId": "a1eda2ba-cf52-4f7e-cae0-d66ba2733d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/S2gen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VByzEVbgU3M5",
        "outputId": "9c0cea34-0a4c-4585-fec2-c057fbedeac0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/S2gen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Detectron2 (it includes Mask R-CNN)\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install -U torch torchvision\n",
        "!pip install git+https://github.com/facebookresearch/detectron2.git\n",
        "# Install Tesseract OCR and pytesseract in a single command\n",
        "!apt-get update && apt-get install -y tesseract-ocr && pip install pytesseract\n"
      ],
      "metadata": {
        "id": "35QK1FCYU42I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.model_zoo import model_zoo\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import build_detection_train_loader\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EJ2RCDeOVDmx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NOTE: PATHS FOR TRAINING BELOW NEED TO HAVE DIFFERENT NAMES FOR EACH MODEL RUN. THIS HAS NOT BEEN DONE YET 12/26/24\n",
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "# Paths to training and validation data\n",
        "train_images_path = '/content/drive/MyDrive/S2gen/data/train/easy/images'\n",
        "train_coco_annotations_file = '/content/drive/MyDrive/S2gen/data/train/easy/coco_annotations.json'\n",
        "val_images_path = '/content/drive/MyDrive/S2gen/data/val/easy/images'\n",
        "val_coco_annotations_file = '/content/drive/MyDrive/S2gen/data/val/easy/coco_annotations.json'\n",
        "\n",
        "# Register the train and validation datasets\n",
        "register_coco_instances(\"my_dataset_train\", {}, train_coco_annotations_file, train_images_path)\n",
        "register_coco_instances(\"my_dataset_val\", {}, val_coco_annotations_file, val_images_path)\n",
        "\n",
        "# Metadata for visualization (optional)\n",
        "my_dataset_metadata = MetadataCatalog.get(\"my_dataset_train\")\n"
      ],
      "metadata": {
        "id": "rmtSgyjWVI6D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the First Model on full images for blocks, connectors, modules, double boxes, dashed lines with arrows, etc..\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "from detectron2.data import MetadataCatalog, DatasetMapper\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.data import build_detection_train_loader\n",
        "from detectron2.data import transforms as T\n",
        "\n",
        "# Paths to images and COCO annotations file\n",
        "images_path = '/content/drive/MyDrive/S2gen/data/train/easy/images'\n",
        "coco_annotations_file = '/content/drive/MyDrive/S2gen/data/train/easy/coco_annotations.json'\n",
        "\n",
        "# Register the dataset with COCO annotations\n",
        "register_coco_instances(\"my_dataset\", {}, coco_annotations_file, images_path)\n",
        "my_dataset_metadata = MetadataCatalog.get(\"my_dataset\")\n",
        "\n",
        "# Set up configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
        "\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset\",)\n",
        "cfg.DATASETS.TEST = ()  # No validation set for now\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "# Set to start training from scratch\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/S2gen/runs/detect/MASK/easy/run1/model_final.pth'\n",
        "\n",
        "\n",
        "\n",
        "# Training configurations\n",
        "cfg.SOLVER.IMS_PER_BATCH = 1  # Adjust batch size based on memory\n",
        "cfg.SOLVER.BASE_LR = 0.00001  # Set base learning rate\n",
        "cfg.SOLVER.MAX_ITER = 100  # Set max iterations for longer training\n",
        "\n",
        "# ROI Heads configurations\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64  # Regions per image in training\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 9  # Only one class, 'dashed_line'\n",
        "\n",
        "\n",
        "# Ensure anchor generator settings match the training configuration\n",
        "# cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[8], [16], [32], [64], [128]]\n",
        "# cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.05, 0.1, 0.2, 0.3]]\n",
        "\n",
        "# Set input size for your images\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = 2176\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 2752\n",
        "cfg.INPUT.MIN_SIZE_TEST = 2176\n",
        "cfg.INPUT.MAX_SIZE_TEST = 2752\n",
        "\n",
        "# Set checkpoint saving every 500 iterations\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
        "\n",
        "# Define output directory\n",
        "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/S2gen/runs/detect/MASK/easy/run1\"\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Custom Trainer to include data augmentation\n",
        "class AugmentedTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        return build_detection_train_loader(\n",
        "            cfg,\n",
        "            mapper=DatasetMapper(\n",
        "                cfg,\n",
        "                is_train=True,\n",
        "                augmentations=[\n",
        "                    T.RandomBrightness(0.8, 1.2),\n",
        "                    T.RandomContrast(0.8, 1.2),\n",
        "                    T.RandomRotation(angle=[-10, 10]),  # Small rotations\n",
        "                    T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
        "                ],\n",
        "            ),\n",
        "        )\n",
        "\n",
        "# Initialize and start training with augmentations\n",
        "trainer = AugmentedTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "DPBoD3YsVLe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da11893-ca59-4b3f-c2ac-823e26aba47e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12/26 17:38:06 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=10, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=36, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[12/26 17:38:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomBrightness(intensity_min=0.8, intensity_max=1.2), RandomContrast(intensity_min=0.8, intensity_max=1.2), RandomRotation(angle=[-10, 10]), RandomFlip(prob=0.5)]\n",
            "[12/26 17:38:12 d2.data.datasets.coco]: Loading /content/drive/MyDrive/S2gen/data/train/easy/coco_annotations.json takes 5.79 seconds.\n",
            "WARNING [12/26 17:38:12 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[12/26 17:38:12 d2.data.datasets.coco]: Loaded 4000 images in COCO format from /content/drive/MyDrive/S2gen/data/train/easy/coco_annotations.json\n",
            "[12/26 17:38:14 d2.data.build]: Removed 0 images with no usable annotations. 4000 images left.\n",
            "[12/26 17:38:15 d2.data.build]: Distribution of instances among all 23 categories:\n",
            "|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
            "|     Block     | 28000        |   Connector   | 48000        |     Cable     | 0            |\n",
            "| Dashed Line.. | 24000        |  Double Box   | 24000        |    Module     | 16000        |\n",
            "|   Call Out    | 40000        | Double Conn.. | 12000        | Call Out Ci.. | 40000        |\n",
            "|     Spare     | 12000        |   Group Box   | 0            | Spider Web .. | 0            |\n",
            "| Vertical St.. | 0            | Double Call.. | 0            |      SFP      | 0            |\n",
            "| Extended Gr.. | 0            | Double Exte.. | 0            | Extended Mo.. | 0            |\n",
            "| Rounded Con.. | 0            | Double Grou.. | 0            | Double Exte.. | 0            |\n",
            "| Double Block  | 0            | Crooked Cable | 0            |               |              |\n",
            "|     total     | 244000       |               |              |               |              |\n",
            "[12/26 17:38:15 d2.data.build]: Using training sampler TrainingSampler\n",
            "[12/26 17:38:15 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[12/26 17:38:15 d2.data.common]: Serializing 4000 elements to byte tensors and concatenating them all ...\n",
            "[12/26 17:38:15 d2.data.common]: Serialized dataset takes 16.05 MiB\n",
            "[12/26 17:38:15 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [12/26 17:38:15 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[12/26 17:38:15 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/S2gen/runs/detect/MASK/easy/run1/model_final.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12/26 17:38:17 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12/26 17:39:12 d2.utils.events]:  eta: 0:03:23  iter: 19  total_loss: 0.1767  loss_cls: 0.04374  loss_box_reg: 0.0674  loss_mask: 0.05369  loss_rpn_cls: 0.0004637  loss_rpn_loc: 0.01992    time: 2.5356  last_time: 2.5299  data_time: 0.0684  last_data_time: 0.0080   lr: 1.9081e-06  max_mem: 12353M\n",
            "[12/26 17:40:03 d2.utils.events]:  eta: 0:02:23  iter: 39  total_loss: 0.1885  loss_cls: 0.04142  loss_box_reg: 0.06901  loss_mask: 0.05893  loss_rpn_cls: 0.0004476  loss_rpn_loc: 0.02143    time: 2.4600  last_time: 2.6373  data_time: 0.0109  last_data_time: 0.0261   lr: 3.9061e-06  max_mem: 12353M\n",
            "[12/26 17:40:54 d2.utils.events]:  eta: 0:01:38  iter: 59  total_loss: 0.204  loss_cls: 0.0433  loss_box_reg: 0.06852  loss_mask: 0.05715  loss_rpn_cls: 0.0004879  loss_rpn_loc: 0.02046    time: 2.4805  last_time: 2.8486  data_time: 0.0128  last_data_time: 0.0095   lr: 5.9041e-06  max_mem: 12353M\n",
            "[12/26 17:41:43 d2.utils.events]:  eta: 0:00:48  iter: 79  total_loss: 0.1903  loss_cls: 0.03107  loss_box_reg: 0.07561  loss_mask: 0.05819  loss_rpn_cls: 0.0004667  loss_rpn_loc: 0.02047    time: 2.4789  last_time: 2.4340  data_time: 0.0121  last_data_time: 0.0136   lr: 7.9021e-06  max_mem: 12353M\n",
            "[12/26 17:42:35 d2.utils.events]:  eta: 0:00:00  iter: 99  total_loss: 0.1944  loss_cls: 0.04753  loss_box_reg: 0.06655  loss_mask: 0.05416  loss_rpn_cls: 0.0004966  loss_rpn_loc: 0.02093    time: 2.4712  last_time: 2.4237  data_time: 0.0133  last_data_time: 0.0083   lr: 9.9001e-06  max_mem: 12353M\n",
            "[12/26 17:42:35 d2.engine.hooks]: Overall training speed: 98 iterations in 0:04:02 (2.4712 s / it)\n",
            "[12/26 17:42:35 d2.engine.hooks]: Total training time: 0:04:07 (0:00:05 on hooks)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run model on validation data. Using one imagefor simplified testing for now.\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "# Define custom class names\n",
        "custom_class_names = [\"Block\", \"Connector\", \"Double Connector\", \"Call Out\", \"Double Box\",\n",
        "                      \"Call Out Circle\", \"Dashed Line with Arrow\", \"Module\", \"Cables\"]\n",
        "\n",
        "# Function to return a list of dictionaries for the dataset (dummy implementation for registration)\n",
        "def get_custom_dataset():\n",
        "    return []\n",
        "\n",
        "# Register the custom dataset\n",
        "custom_dataset_name = \"custom_val_dataset\"\n",
        "if custom_dataset_name in DatasetCatalog.list():\n",
        "    DatasetCatalog.remove(custom_dataset_name)\n",
        "    MetadataCatalog.remove(custom_dataset_name)\n",
        "\n",
        "DatasetCatalog.register(custom_dataset_name, get_custom_dataset)\n",
        "MetadataCatalog.get(custom_dataset_name).thing_classes = custom_class_names\n",
        "\n",
        "# Paths\n",
        "val_image_path = '/content/drive/MyDrive/S2gen/data/val/easy/diagram_8001.png'\n",
        "predictions_json_path_1 = '/content/drive/MyDrive/S2gen/runs/easy_predictions_1/predictions_1.json'\n",
        "os.makedirs(os.path.dirname(predictions_json_path_1), exist_ok=True)\n",
        "\n",
        "# Configure the first model\n",
        "cfg1 = get_cfg()\n",
        "cfg1.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
        "cfg1.MODEL.WEIGHTS = '/content/drive/MyDrive/S2gen/runs/detect/MASK/easy/run1/model_final.pth'\n",
        "cfg1.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg1.MODEL.ROI_HEADS.NUM_CLASSES = len(custom_class_names)\n",
        "cfg1.INPUT.MIN_SIZE_TEST = 2176\n",
        "cfg1.INPUT.MAX_SIZE_TEST = 2752\n",
        "\n",
        "# Set the dataset metadata for the custom dataset\n",
        "cfg1.DATASETS.TRAIN = (custom_dataset_name,)\n",
        "cfg1.DATASETS.TEST = (custom_dataset_name,)\n",
        "\n",
        "# Create predictor and load image\n",
        "predictor1 = DefaultPredictor(cfg1)\n",
        "image = cv2.imread(val_image_path)\n",
        "\n",
        "# Run inference\n",
        "outputs1 = predictor1(image)\n",
        "\n",
        "# Prepare COCO-style JSON output\n",
        "coco_annotations_1 = {\n",
        "    \"images\": [{\"file_name\": os.path.basename(val_image_path), \"height\": image.shape[0], \"width\": image.shape[1], \"id\": 1}],\n",
        "    \"annotations\": [],\n",
        "    \"categories\": [{\"id\": i, \"name\": name} for i, name in enumerate(custom_class_names)]\n",
        "}\n",
        "\n",
        "# Convert Detectron2 predictions to COCO-style format\n",
        "instances = outputs1[\"instances\"].to(\"cpu\")\n",
        "for i in range(len(instances)):\n",
        "    bbox = instances.pred_boxes[i].tensor.numpy().tolist()[0]\n",
        "    category_id = int(instances.pred_classes[i].item())\n",
        "    coco_annotations_1[\"annotations\"].append({\n",
        "        \"id\": i,\n",
        "        \"image_id\": 1,\n",
        "        \"category_id\": category_id,\n",
        "        \"bbox\": [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]],  # Convert to COCO bbox format\n",
        "        \"area\": float((bbox[2] - bbox[0]) * (bbox[3] - bbox[1])),\n",
        "        \"iscrowd\": 0\n",
        "    })\n",
        "\n",
        "# Save the JSON file for the first model's predictions\n",
        "with open(predictions_json_path_1, 'w') as f:\n",
        "    json.dump(coco_annotations_1, f)\n",
        "\n",
        "print(f\"First model predictions saved in COCO JSON format at: {predictions_json_path_1}\")\n"
      ],
      "metadata": {
        "id": "tfNzWw1btsNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420449fc-44ab-4578-8f4a-4d369b329268"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12/26 17:42:36 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/S2gen/runs/detect/MASK/easy/run1/model_final.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First model predictions saved in COCO JSON format at: /content/drive/MyDrive/S2gen/runs/easy_predictions_1/predictions_1.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Training and validation data for second model\n",
        "\n",
        "# Paths to training and validation data\n",
        "train_images_path2 = '/content/drive/MyDrive/S2gen/data/train/easy/sliced_images'\n",
        "train_coco_annotations_file2 = '/content/drive/MyDrive/S2gen/data/train/easy/sliced_coco_annotations.json'\n",
        "val_images_path2 = '/content/drive/MyDrive/S2gen/data/val/easy/sliced_images'\n",
        "val_coco_annotations_file2 = '/content/drive/MyDrive/S2gen/data/val/easy/coco_annotations.json'\n",
        "\n",
        "# Register the train and validation datasets\n",
        "register_coco_instances(\"my_dataset_train2\", {}, train_coco_annotations_file2, train_images_path2)\n",
        "register_coco_instances(\"my_dataset_val2\", {}, val_coco_annotations_file2, val_images_path2)\n",
        "\n",
        "# Metadata for visualization (optional)\n",
        "my_dataset_metadata = MetadataCatalog.get(\"my_dataset_train2\")\n"
      ],
      "metadata": {
        "id": "cugir92on5_O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the second model on cables only\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "from detectron2.data import MetadataCatalog, DatasetMapper\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.data import build_detection_train_loader\n",
        "from detectron2.data import transforms as T\n",
        "\n",
        "# Paths to images and COCO annotations file\n",
        "images_path = '/content/drive/MyDrive/S2gen/data/train/easy/sliced_images'\n",
        "coco_annotations_file = '/content/drive/MyDrive/S2gen/data/train/easy/sliced_coco_annotations.json'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Register the dataset with COCO annotations\n",
        "register_coco_instances(\"my_dataset_train2\", {}, coco_annotations_file, images_path)\n",
        "my_dataset_metadata = MetadataCatalog.get(\"my_dataset_train2\")\n",
        "\n",
        "\n",
        "# Set up configuration\n",
        "cfg3 = get_cfg()\n",
        "cfg3.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
        "\n",
        "cfg3.DATASETS.TRAIN = (\"my_dataset_train2\",)\n",
        "cfg3.DATASETS.TEST = ()  # No validation set for now\n",
        "cfg3.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "# Set to start training from scratch\n",
        "cfg3.MODEL.WEIGHTS = \"/content/drive/MyDrive/S2gen/runs/detect/MASK/r101_run2_scratch/model_0019999.pth\"\n",
        "\n",
        "\n",
        "\n",
        "# Training configurations\n",
        "cfg3.SOLVER.IMS_PER_BATCH = 1  # Adjust batch size based on memory\n",
        "cfg3.SOLVER.BASE_LR = 0.00001  # Set base learning rate\n",
        "cfg3.SOLVER.MAX_ITER = 100  # Set max iterations for longer training\n",
        "\n",
        "# ROI Heads configurations\n",
        "cfg3.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64  # Regions per image in training\n",
        "cfg3.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only one class, 'dashed_line'\n",
        "\n",
        "\n",
        "#Ensure anchor generator settings match the training configuration\n",
        "cfg3.MODEL.ANCHOR_GENERATOR.SIZES = [[8], [16], [32], [64], [128]]\n",
        "cfg3.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.05, 0.1, 0.2, 0.3]]\n",
        "\n",
        "# Set input size for your images\n",
        "cfg3.INPUT.MIN_SIZE_TRAIN = 435\n",
        "cfg3.INPUT.MAX_SIZE_TRAIN = 550\n",
        "cfg3.INPUT.MIN_SIZE_TEST = 435\n",
        "cfg3.INPUT.MAX_SIZE_TEST = 550\n",
        "\n",
        "\n",
        "\n",
        "# Set checkpoint saving every 500 iterations\n",
        "cfg3.SOLVER.CHECKPOINT_PERIOD = 500\n",
        "\n",
        "# Define output directory\n",
        "cfg3.OUTPUT_DIR = \"/content/drive/MyDrive/S2gen/runs/detect/MASK/r101_run3_scratch/\"\n",
        "os.makedirs(cfg3.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Custom Trainer to include data augmentation\n",
        "class AugmentedTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        return build_detection_train_loader(\n",
        "            cfg,\n",
        "            mapper=DatasetMapper(\n",
        "                cfg,\n",
        "                is_train=True,\n",
        "                augmentations=[\n",
        "                    T.RandomBrightness(0.8, 1.2),\n",
        "                    T.RandomContrast(0.8, 1.2),\n",
        "                    T.RandomRotation(angle=[-10, 10]),  # Small rotations\n",
        "                    T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
        "                ],\n",
        "            ),\n",
        "        )\n",
        "\n",
        "# Initialize and start training with augmentations\n",
        "trainer = AugmentedTrainer(cfg3)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlWI86Q2mj2u",
        "outputId": "4a3347bd-9683-49eb-8edc-566cefa8dc50"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12/26 17:42:39 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[12/26 17:42:39 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomBrightness(intensity_min=0.8, intensity_max=1.2), RandomContrast(intensity_min=0.8, intensity_max=1.2), RandomRotation(angle=[-10, 10]), RandomFlip(prob=0.5)]\n",
            "WARNING [12/26 17:42:39 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[12/26 17:42:39 d2.data.datasets.coco]: Loaded 857 images in COCO format from /content/drive/MyDrive/S2gen/data/train/easy/sliced_coco_annotations.json\n",
            "[12/26 17:42:39 d2.data.build]: Removed 0 images with no usable annotations. 857 images left.\n",
            "[12/26 17:42:39 d2.data.build]: Distribution of instances among all 23 categories:\n",
            "|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
            "|     Block     | 7806         |   Connector   | 0            |     Cable     | 0            |\n",
            "| Dashed Line.. | 0            |  Double Box   | 0            |    Module     | 0            |\n",
            "|   Call Out    | 0            | Double Conn.. | 0            | Call Out Ci.. | 0            |\n",
            "|     Spare     | 0            |   Group Box   | 0            | Spider Web .. | 0            |\n",
            "| Vertical St.. | 0            | Double Call.. | 0            |      SFP      | 0            |\n",
            "| Extended Gr.. | 0            | Double Exte.. | 0            | Extended Mo.. | 0            |\n",
            "| Rounded Con.. | 0            | Double Grou.. | 0            | Double Exte.. | 0            |\n",
            "| Double Block  | 0            | Crooked Cable | 0            |               |              |\n",
            "|     total     | 7806         |               |              |               |              |\n",
            "[12/26 17:42:40 d2.data.build]: Using training sampler TrainingSampler\n",
            "[12/26 17:42:40 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[12/26 17:42:40 d2.data.common]: Serializing 857 elements to byte tensors and concatenating them all ...\n",
            "[12/26 17:42:40 d2.data.common]: Serialized dataset takes 0.66 MiB\n",
            "[12/26 17:42:40 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [12/26 17:42:40 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[12/26 17:42:40 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/S2gen/runs/detect/MASK/r101_run2_scratch/model_0019999.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12/26 17:42:41 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[12/26 17:42:46 d2.utils.events]:  eta: 0:00:17  iter: 19  total_loss: 0.1883  loss_cls: 0.01971  loss_box_reg: 0.07431  loss_mask: 0.06602  loss_rpn_cls: 0.002942  loss_rpn_loc: 0.01657    time: 0.2136  last_time: 0.1696  data_time: 0.0161  last_data_time: 0.0048   lr: 1.9081e-06  max_mem: 12353M\n",
            "[12/26 17:42:50 d2.utils.events]:  eta: 0:00:12  iter: 39  total_loss: 0.1789  loss_cls: 0.009451  loss_box_reg: 0.06867  loss_mask: 0.05673  loss_rpn_cls: 0.001435  loss_rpn_loc: 0.0156    time: 0.2002  last_time: 0.1564  data_time: 0.0035  last_data_time: 0.0026   lr: 3.9061e-06  max_mem: 12353M\n",
            "[12/26 17:42:53 d2.utils.events]:  eta: 0:00:06  iter: 59  total_loss: 0.2174  loss_cls: 0.01692  loss_box_reg: 0.09736  loss_mask: 0.06854  loss_rpn_cls: 0.002223  loss_rpn_loc: 0.01088    time: 0.1884  last_time: 0.1821  data_time: 0.0030  last_data_time: 0.0031   lr: 5.9041e-06  max_mem: 12353M\n",
            "[12/26 17:42:57 d2.utils.events]:  eta: 0:00:03  iter: 79  total_loss: 0.2511  loss_cls: 0.0101  loss_box_reg: 0.09056  loss_mask: 0.1034  loss_rpn_cls: 0.003561  loss_rpn_loc: 0.0146    time: 0.1855  last_time: 0.1602  data_time: 0.0085  last_data_time: 0.0027   lr: 7.9021e-06  max_mem: 12353M\n",
            "[12/26 17:43:01 d2.utils.events]:  eta: 0:00:00  iter: 99  total_loss: 0.1851  loss_cls: 0.01854  loss_box_reg: 0.06371  loss_mask: 0.07372  loss_rpn_cls: 0.004029  loss_rpn_loc: 0.01472    time: 0.1790  last_time: 0.1434  data_time: 0.0025  last_data_time: 0.0024   lr: 9.9001e-06  max_mem: 12353M\n",
            "[12/26 17:43:01 d2.engine.hooks]: Overall training speed: 98 iterations in 0:00:17 (0.1791 s / it)\n",
            "[12/26 17:43:01 d2.engine.hooks]: Total training time: 0:00:19 (0:00:01 on hooks)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run second model on Cables only using  one sliced image. sliced images.Custom Anchor boxes used, should be adjusted for performance at a later date.\n",
        "# Predictions saved in JSON with location data adjusted to true full image location.\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from pycocotools import mask as mask_utils\n",
        "import numpy as np\n",
        "\n",
        "# Directory setup for sliced images and JSON output for the second model\n",
        "sliced_images_folder = '/content/drive/MyDrive/S2gen/data/val/easy/sliced_images'\n",
        "predictions_json_path_2 = '/content/drive/MyDrive/S2gen/runs/easy_predictions_2/predictions_2.json'\n",
        "os.makedirs(sliced_images_folder, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(predictions_json_path_2), exist_ok=True)\n",
        "\n",
        "# Slicing parameters\n",
        "slice_width, slice_height = 550, 435\n",
        "num_slices_width, num_slices_height = 7, 6\n",
        "overlap_percentage_width, overlap_percentage_height = 0.25, 0.25\n",
        "\n",
        "val_image_path = '/content/drive/MyDrive/S2gen/data/val/easy/diagram_8001.png'\n",
        "\n",
        "# Configure the second model\n",
        "cfg2 = get_cfg()\n",
        "cfg2.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
        "cfg2.MODEL.WEIGHTS = \"/content/drive/MyDrive/S2gen/runs/detect/MASK/r101_run2_scratch/model_0019999.pth\"\n",
        "cfg2.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
        "cfg2.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only one class, 'Cables'\n",
        "cfg2.INPUT.MIN_SIZE_TEST = 435\n",
        "cfg2.INPUT.MAX_SIZE_TEST = 550\n",
        "\n",
        "# Ensure anchor generator settings match the training configuration\n",
        "cfg2.MODEL.ANCHOR_GENERATOR.SIZES = [[8], [16], [32], [64], [128]]\n",
        "cfg2.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.05, 0.1, 0.2, 0.3]]\n",
        "\n",
        "predictor2 = DefaultPredictor(cfg2)\n",
        "\n",
        "# COCO-style JSON output for second model with category ID set for 'Cables'\n",
        "coco_annotations_2 = {\n",
        "    \"images\": [],\n",
        "    \"annotations\": [],\n",
        "    \"categories\": [{\"id\": 8, \"name\": \"Cable\"}]  # Set category ID to 8 for 'Cables'\n",
        "}\n",
        "\n",
        "# Load the image and prepare slicing\n",
        "image = cv2.imread(val_image_path)\n",
        "original_height, original_width, _ = image.shape\n",
        "step_width = int(slice_width * (1 - overlap_percentage_width))\n",
        "step_height = int(slice_height * (1 - overlap_percentage_height))\n",
        "annotation_id = 0\n",
        "\n",
        "# Slice the image and run inference on each slice\n",
        "for i in range(num_slices_height):\n",
        "    for j in range(num_slices_width):\n",
        "        x_start = j * step_width\n",
        "        y_start = i * step_height\n",
        "        x_end = min(x_start + slice_width, original_width)\n",
        "        y_end = min(y_start + slice_height, original_height)\n",
        "\n",
        "        # Slice and save image\n",
        "        slice_img = image[y_start:y_end, x_start:x_end]\n",
        "        slice_name = f\"diagram_8001_{i}_{j}.png\"\n",
        "        slice_path = os.path.join(sliced_images_folder, slice_name)\n",
        "        cv2.imwrite(slice_path, slice_img)\n",
        "\n",
        "        # Run inference on the slice\n",
        "        outputs2 = predictor2(slice_img)\n",
        "        instances = outputs2[\"instances\"].to(\"cpu\")\n",
        "\n",
        "        # Add slice info to JSON with a unique image_id for each slice\n",
        "        image_id = i * num_slices_width + j + 1  # Unique ID for each slice\n",
        "        coco_annotations_2[\"images\"].append({\n",
        "            \"file_name\": slice_name,\n",
        "            \"height\": slice_img.shape[0],\n",
        "            \"width\": slice_img.shape[1],\n",
        "            \"id\": image_id\n",
        "        })\n",
        "\n",
        "        # Convert predictions to COCO-style annotations with adjusted coordinates\n",
        "        for k in range(len(instances)):\n",
        "            bbox = instances.pred_boxes[k].tensor.numpy().tolist()[0]\n",
        "            mask = instances.pred_masks[k].numpy()\n",
        "            encoded_mask = mask_utils.encode(np.asfortranarray(mask.astype(np.uint8)))\n",
        "            encoded_mask[\"counts\"] = encoded_mask[\"counts\"].decode(\"utf-8\")\n",
        "\n",
        "            # Adjust bbox position to map to original image coordinates\n",
        "            adjusted_bbox = [\n",
        "                bbox[0] + x_start,  # Adjust x coordinate to full image\n",
        "                bbox[1] + y_start,  # Adjust y coordinate to full image\n",
        "                bbox[2] - bbox[0],  # Width remains the same\n",
        "                bbox[3] - bbox[1]   # Height remains the same\n",
        "            ]\n",
        "\n",
        "            # Add adjusted annotations to the JSON\n",
        "            coco_annotations_2[\"annotations\"].append({\n",
        "                \"id\": annotation_id,\n",
        "                \"image_id\": image_id,  # Correct unique image_id for each slice\n",
        "                \"category_id\": 8,  # Set category_id to 8 for 'Cables'\n",
        "                \"bbox\": adjusted_bbox,\n",
        "                \"segmentation\": encoded_mask,\n",
        "                \"area\": float(mask.sum()),\n",
        "                \"iscrowd\": 0\n",
        "            })\n",
        "            annotation_id += 1\n",
        "\n",
        "# Save JSON file for the second model's predictions\n",
        "with open(predictions_json_path_2, 'w') as f:\n",
        "    json.dump(coco_annotations_2, f)\n",
        "\n",
        "print(f\"Second model predictions saved in COCO JSON format at: {predictions_json_path_2}\")\n"
      ],
      "metadata": {
        "id": "Q26JDf4btsPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea296135-e680-4b7b-d68d-08fc577aa10d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12/26 17:43:03 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/S2gen/runs/detect/MASK/r101_run2_scratch/model_0019999.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second model predictions saved in COCO JSON format at: /content/drive/MyDrive/S2gen/runs/easy_predictions_2/predictions_2.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine predictions from both models into one COCO JSON format file.\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "# Load both JSON files\n",
        "with open(predictions_json_path_1, 'r') as f1:\n",
        "    coco_annotations_1 = json.load(f1)\n",
        "\n",
        "with open(predictions_json_path_2, 'r') as f2:\n",
        "    coco_annotations_2 = json.load(f2)\n",
        "\n",
        "# Combine annotations and images\n",
        "combined_annotations = {\n",
        "    \"images\": coco_annotations_1[\"images\"],  # Use the original image info\n",
        "    \"annotations\": coco_annotations_1[\"annotations\"] + coco_annotations_2[\"annotations\"],\n",
        "    \"categories\": coco_annotations_1[\"categories\"]\n",
        "}\n",
        "\n",
        "# Save the combined JSON file\n",
        "combined_json_path = \"/content/drive/MyDrive/S2gen/runs/easy_predictions_combined/predictions_combined.json\"\n",
        "os.makedirs(os.path.dirname(combined_json_path), exist_ok=True)\n",
        "with open(combined_json_path, 'w') as f:\n",
        "    json.dump(combined_annotations, f)\n",
        "\n",
        "print(f\"Combined predictions saved in COCO JSON format at: {combined_json_path}\")\n"
      ],
      "metadata": {
        "id": "o0uKVtlZtsRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6d6737-8129-4d55-ef15-eec8c4d9adf9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined predictions saved in COCO JSON format at: /content/drive/MyDrive/S2gen/runs/easy_predictions_combined/predictions_combined.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attach predictions to image for visualization.\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "from pycocotools import mask as mask_utils\n",
        "\n",
        "# Paths\n",
        "original_image_path = '/content/drive/MyDrive/S2gen/data/val/easy/diagram_8001.png'\n",
        "combined_json_path = '/content/drive/MyDrive/S2gen/runs/easy_predictions_combined/predictions_combined.json'\n",
        "output_dir = '/content/drive/MyDrive/S2gen/runs/easy_predictions_combined/annotated_image'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load the original image\n",
        "original_image = cv2.imread(original_image_path)\n",
        "\n",
        "# Load combined predictions\n",
        "with open(combined_json_path, 'r') as f:\n",
        "    combined_predictions = json.load(f)\n",
        "\n",
        "# Overlay each annotation on the original image\n",
        "for annotation in combined_predictions['annotations']:\n",
        "    # Get the bounding box and category\n",
        "    bbox = annotation['bbox']\n",
        "    x_start, y_start, width, height = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
        "    category_id = annotation['category_id']\n",
        "\n",
        "    # Draw the bounding box\n",
        "    color = (0, 255, 0)  # Green for bounding boxes\n",
        "    cv2.rectangle(original_image, (x_start, y_start), (x_start + width, y_start + height), color, 2)\n",
        "\n",
        "    # Draw the category label above the bounding box\n",
        "    label = combined_predictions['categories'][category_id]['name']\n",
        "    cv2.putText(original_image, label, (x_start, y_start - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    # Draw segmentation mask if available\n",
        "    if 'segmentation' in annotation:\n",
        "        segmentation = annotation['segmentation']\n",
        "        if isinstance(segmentation, dict):  # RLE format\n",
        "            mask = mask_utils.decode(segmentation).astype(np.uint8) * 255  # Decode the RLE mask\n",
        "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cv2.drawContours(original_image, contours, -1, (255, 0, 0), 2)  # Blue for masks\n",
        "        elif isinstance(segmentation, list):  # Polygon format\n",
        "            for seg in segmentation:\n",
        "                poly = np.array(seg).reshape((-1, 2)).astype(np.int32)\n",
        "                cv2.polylines(original_image, [poly], isClosed=True, color=(255, 0, 0), thickness=2)\n",
        "\n",
        "# Save the annotated image\n",
        "output_image_path = os.path.join(output_dir, 'diagram_8001_annotated.png')\n",
        "cv2.imwrite(output_image_path, original_image)\n",
        "\n",
        "print(f\"Annotated image saved at: {output_image_path}\")\n"
      ],
      "metadata": {
        "id": "uFyIgxLCtsTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e14834-c56d-46ee-a6d3-f6fd38da61a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotated image saved at: /content/drive/MyDrive/S2gen/runs/easy_predictions_combined/annotated_image/diagram_8001_annotated.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print image for visulization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Load an image using OpenCV (use the correct path to your image)\n",
        "image = cv2.imread('/content/drive/MyDrive/S2gen/runs/easy_predictions_combined/annotated_image/diagram_8001_annotated.png')\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "gwdZ74oEeFGT",
        "outputId": "c3f450bf-820f-45cd-f848-688e68845423"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cy7RfkVcVvz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions to SysML 2.0.\n",
        "\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "\n",
        "# Load the combined predictions JSON file\n",
        "combined_json_path = '/content/drive/MyDrive/S2gen/runs/easy_predictions_combined/predictions_combined.json'\n",
        "with open(combined_json_path, 'r') as f:\n",
        "    predictions = json.load(f)\n",
        "\n",
        "# Load the image to extract text from blocks\n",
        "image_path = \"/content/drive/MyDrive/S2gen/data/val/easy/diagram_8001.png\"  # Update with the correct path\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Check if the image was loaded successfully\n",
        "if image is None:\n",
        "    raise FileNotFoundError(f\"Image not found at path: {image_path}\")\n",
        "\n",
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "\n",
        "def extract_text_from_bbox(image, bbox):\n",
        "    # Use the full bounding box dimensions\n",
        "    x, y, w, h = map(int, bbox)\n",
        "\n",
        "    # Focus only on the top 20% of the bounding box\n",
        "    top_section_height = int(h * 0.2)\n",
        "    cropped_image = image[y:y + top_section_height, x:x + w]\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply resizing (magnification) to enhance OCR performance\n",
        "    magnified_image = cv2.resize(gray, None, fx=4.0, fy=4.0, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Apply adaptive thresholding to improve text clarity\n",
        "    thresh = cv2.adaptiveThreshold(magnified_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                   cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "    # OCR configuration focused on capturing single lines or words\n",
        "    custom_config = r'--psm 7 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-'\n",
        "    text = pytesseract.image_to_string(thresh, config=custom_config).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "# Initialize SysML part definitions and interface connections\n",
        "block_parts = []\n",
        "module_parts = []\n",
        "connector_parts = []\n",
        "cable_parts = []\n",
        "interface_connections = []\n",
        "\n",
        "# Define mappings for category IDs to names (use class names from your model)\n",
        "category_id_to_name = {\n",
        "    0: 'Block',\n",
        "    1: 'Connector',\n",
        "    2: 'Double Connector',\n",
        "    3: 'Cable',\n",
        "    4: 'Dashed Line with Arrow',\n",
        "    5: 'Module',\n",
        "    6: 'Double Box',\n",
        "    7: 'Call Out',\n",
        "    8: 'Cables',\n",
        "    9: 'Double Connector',\n",
        "    10: 'Call Out Circle',\n",
        "}\n",
        "\n",
        "# Organize parts based on categories\n",
        "for annotation in predictions[\"annotations\"]:\n",
        "    category_name = category_id_to_name.get(annotation[\"category_id\"], None)\n",
        "    part_id = f\"{category_name.lower()}{annotation['id']}\"\n",
        "\n",
        "    if category_name == \"Block\":\n",
        "        # Extract text only for blocks\n",
        "        block_name = extract_text_from_bbox(image, annotation[\"bbox\"])\n",
        "        block_parts.append(f\"part {part_id}: Block {{ attribute name = \\\"{block_name}\\\"; }}\")\n",
        "    elif category_name == \"Module\":\n",
        "        module_parts.append(f\"part {part_id}: Module;\")\n",
        "    elif category_name == \"Connector\":\n",
        "        connector_parts.append(f\"part {part_id}: Connector;\")\n",
        "    elif category_name == \"Cable\":\n",
        "        cable_parts.append(f\"part {part_id}: Cable {{ attribute id = {annotation['id']}; }};\")\n",
        "\n",
        "# Generate connections based on SysML rules\n",
        "def boxes_touch(bbox1, bbox2):\n",
        "    x1, y1, w1, h1 = bbox1\n",
        "    x2, y2, w2, h2 = bbox2\n",
        "    return not (x1 + w1 < x2 or x2 + w2 < x1 or y1 + h1 < y2 or y2 + h2 < y1)\n",
        "\n",
        "for cable in [ann for ann in predictions[\"annotations\"] if category_id_to_name.get(ann[\"category_id\"]) == \"Cable\"]:\n",
        "    for other_cable in [ann for ann in predictions[\"annotations\"] if ann[\"id\"] != cable[\"id\"] and category_id_to_name.get(ann[\"category_id\"]) == \"Cable\"]:\n",
        "        if boxes_touch(cable[\"bbox\"], other_cable[\"bbox\"]):\n",
        "            interface_connections.append(f\"interface sameCableConnection: BinaryInterface connect cable{cable['id']} to cable{other_cable['id']} using Cable;\")\n",
        "\n",
        "    for connector in [ann for ann in predictions[\"annotations\"] if category_id_to_name.get(ann[\"category_id\"]) == \"Connector\"]:\n",
        "        if boxes_touch(cable[\"bbox\"], connector[\"bbox\"]):\n",
        "            interface_connections.append(f\"interface cableConnectorConnection: BinaryInterface connect cable{cable['id']} to connector{connector['id']} using Cable;\")\n",
        "\n",
        "for connector in [ann for ann in predictions[\"annotations\"] if category_id_to_name.get(ann[\"category_id\"]) == \"Connector\"]:\n",
        "    for block in [ann for ann in predictions[\"annotations\"] if category_id_to_name.get(ann[\"category_id\"]) == \"Block\"]:\n",
        "        if boxes_touch(connector[\"bbox\"], block[\"bbox\"]):\n",
        "            interface_connections.append(f\"interface blockConnectorConnection: BinaryInterface connect connector{connector['id']} to block{block['id']} using Connector;\")\n",
        "\n",
        "    for module in [ann for ann in predictions[\"annotations\"] if category_id_to_name.get(ann[\"category_id\"]) == \"Module\"]:\n",
        "        if boxes_touch(connector[\"bbox\"], module[\"bbox\"]):\n",
        "            interface_connections.append(f\"interface moduleConnectorConnection: BinaryInterface connect connector{connector['id']} to module{module['id']} using Connector;\")\n",
        "\n",
        "for module in [ann for ann in predictions[\"annotations\"] if category_id_to_name.get(ann[\"category_id\"]) == \"Module\"]:\n",
        "    for block in [ann for ann in predictions[\"annotations\"] if category_id_to_name.get(ann[\"category_id\"]) == \"Block\"]:\n",
        "        if boxes_touch(module[\"bbox\"], block[\"bbox\"]):\n",
        "            interface_connections.append(f\"interface moduleBlockConnection: BinaryInterface connect module{module['id']} to block{block['id']} using Module;\")\n",
        "\n",
        "for dashed_line in [ann for ann in predictions[\"annotations\"] if category_id_to_name.get(ann[\"category_id\"]) == \"Dashed Line with Arrow\"]:\n",
        "    for cable in [ann for ann in predictions[\"annotations\"] if category_id_to_name.get(ann[\"category_id\"]) == \"Cable\"]:\n",
        "        combined_bbox = [\n",
        "            min(dashed_line[\"bbox\"][0], cable[\"bbox\"][0]),\n",
        "            min(dashed_line[\"bbox\"][1], cable[\"bbox\"][1]),\n",
        "            max(dashed_line[\"bbox\"][2] + dashed_line[\"bbox\"][0], cable[\"bbox\"][2] + cable[\"bbox\"][0]) - min(dashed_line[\"bbox\"][0], cable[\"bbox\"][0]),\n",
        "            max(dashed_line[\"bbox\"][3] + dashed_line[\"bbox\"][1], cable[\"bbox\"][3] + cable[\"bbox\"][1]) - min(dashed_line[\"bbox\"][1], cable[\"bbox\"][1])\n",
        "        ]\n",
        "\n",
        "        for block in [ann for ann in predictions[\"annotations\"] if category_id_to_name.get(ann[\"category_id\"]) == \"Block\"]:\n",
        "            if boxes_touch(combined_bbox, block[\"bbox\"]):\n",
        "                interface_connections.append(f\"interface dashedLineBlockConnection: BinaryInterface connect dashedlinewitharrow{dashed_line['id']} to block{block['id']} using DashedLineWithArrow;\")\n",
        "\n",
        "    for double_box in [ann for ann in predictions[\"annotations\"] if category_id_to_name.get(ann[\"category_id\"]) == \"Double Box\"]:\n",
        "        if boxes_touch(dashed_line[\"bbox\"], double_box[\"bbox\"]):\n",
        "            interface_connections.append(f\"interface dashedLineDoubleBoxConnection: BinaryInterface connect dashedlinewitharrow{dashed_line['id']} to doublebox{double_box['id']} using DashedLineWithArrow;\")\n",
        "\n",
        "# Compile SysML code\n",
        "sysml_code = \"package ConnectionExample {\\n\\n\"\n",
        "sysml_code += \"    // Part definitions for Blocks, Modules, Connectors, and Cables\\n\"\n",
        "sysml_code += \"    \" + \"\\n    \".join(block_parts + module_parts) + \"\\n\\n\"\n",
        "sysml_code += \"    // Connector definitions\\n\"\n",
        "sysml_code += \"    \" + \"\\n    \".join(connector_parts) + \"\\n\\n\"\n",
        "sysml_code += \"    // Cable parts with unique identifiers\\n\"\n",
        "sysml_code += \"    \" + \"\\n    \".join(cable_parts) + \"\\n\\n\"\n",
        "sysml_code += \"    // Interface definitions for connections between parts\\n\"\n",
        "sysml_code += \"    \" + \"\\n    \".join(interface_connections) + \"\\n\\n\"\n",
        "sysml_code += \"}\\n\"\n",
        "\n",
        "# Save SysML output to a file\n",
        "sysml_output_path = '/content/drive/MyDrive/S2gen/runs/easy_sysml2_output.txt'\n",
        "with open(sysml_output_path, 'w') as f:\n",
        "    f.write(sysml_code)\n",
        "\n",
        "print(f\"SysML code saved at: {sysml_output_path}\")\n"
      ],
      "metadata": {
        "id": "ShzDk29fJcJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2327d4-3fac-4135-935b-0049ac9ca7fe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SysML code saved at: /content/drive/MyDrive/S2gen/runs/easy_sysml2_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/S2gen/runs/easy_sysml2_output.txt'\n",
        "\n",
        "# Open and read the file\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Print the content\n",
        "print(content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZbulrb3EcGI",
        "outputId": "2cf6be81-af76-4612-b32a-fc8c078ae008"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "package ConnectionExample {\n",
            "\n",
            "    // Part definitions for Blocks, Modules, Connectors, and Cables\n",
            "    part block27: Block { attribute name = \"\"; }\n",
            "    part block35: Block { attribute name = \"\"; }\n",
            "    part block36: Block { attribute name = \"\"; }\n",
            "    part block38: Block { attribute name = \"\"; }\n",
            "    part block41: Block { attribute name = \"\"; }\n",
            "    part block47: Block { attribute name = \"L BLOCK-3\"; }\n",
            "    part module46: Module;\n",
            "    part module48: Module;\n",
            "\n",
            "    // Connector definitions\n",
            "    part connector0: Connector;\n",
            "    part connector1: Connector;\n",
            "    part connector2: Connector;\n",
            "    part connector8: Connector;\n",
            "    part connector10: Connector;\n",
            "    part connector18: Connector;\n",
            "    part connector21: Connector;\n",
            "    part connector22: Connector;\n",
            "    part connector24: Connector;\n",
            "    part connector34: Connector;\n",
            "    part connector44: Connector;\n",
            "    part connector45: Connector;\n",
            "\n",
            "    // Cable parts with unique identifiers\n",
            "    part cable9: Cable { attribute id = 9; };\n",
            "    part cable16: Cable { attribute id = 16; };\n",
            "    part cable26: Cable { attribute id = 26; };\n",
            "    part cable29: Cable { attribute id = 29; };\n",
            "    part cable30: Cable { attribute id = 30; };\n",
            "    part cable32: Cable { attribute id = 32; };\n",
            "\n",
            "    // Interface definitions for connections between parts\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector0 to block38 using Connector;\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector1 to block36 using Connector;\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector2 to block27 using Connector;\n",
            "    interface moduleConnectorConnection: BinaryInterface connect connector2 to module48 using Connector;\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector8 to block27 using Connector;\n",
            "    interface moduleConnectorConnection: BinaryInterface connect connector8 to module46 using Connector;\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector10 to block47 using Connector;\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector18 to block36 using Connector;\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector21 to block36 using Connector;\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector22 to block47 using Connector;\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector24 to block36 using Connector;\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector34 to block47 using Connector;\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector44 to block38 using Connector;\n",
            "    interface blockConnectorConnection: BinaryInterface connect connector45 to block47 using Connector;\n",
            "    interface moduleBlockConnection: BinaryInterface connect module46 to block27 using Module;\n",
            "    interface moduleBlockConnection: BinaryInterface connect module48 to block27 using Module;\n",
            "\n",
            "}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}